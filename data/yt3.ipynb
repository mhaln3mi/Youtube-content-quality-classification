{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib2to3.pgen2 import token\n",
    "import os\n",
    "from urllib import response\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "youtube = build('youtube', 'v3', developerKey='AIzaSyArAXXQzyo8XBs5o5lm5aKL8_aRB_YDG1M')\n",
    "\n",
    "\n",
    "\n",
    "box = [['Name', 'Comments', 'Time', 'Likes', 'Reply Count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments_with_replies(id):\n",
    "    data = youtube.commentThreads().list(part='snippet', videoId=id, maxResults='100', textFormat=\"plainText\").execute()\n",
    "        \n",
    "    for i in data[\"items\"]:\n",
    "        name = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"authorDisplayName\"]\n",
    "        comment = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"textDisplay\"]\n",
    "        published_at = i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt']\n",
    "        likes = i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount']\n",
    "        replies = i[\"snippet\"]['totalReplyCount']\n",
    "            \n",
    "        box.append([name, comment, published_at, likes, replies])\n",
    "            \n",
    "        totalReplyCount = i[\"snippet\"]['totalReplyCount']\n",
    "            \n",
    "\n",
    "    while (\"nextPageToken\" in data):\n",
    "            \n",
    "        data = youtube.commentThreads().list(part='snippet', videoId=id, pageToken=data[\"nextPageToken\"],\n",
    "                                             maxResults='100', textFormat=\"plainText\").execute()\n",
    "                                             \n",
    "        for i in data[\"items\"]:\n",
    "            name = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"authorDisplayName\"]\n",
    "            comment = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"textDisplay\"]\n",
    "            published_at = i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt']\n",
    "            likes = i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount']\n",
    "            replies = i[\"snippet\"]['totalReplyCount']\n",
    "\n",
    "            box.append([name, comment, published_at, likes, replies])\n",
    "\n",
    "            totalReplyCount = i[\"snippet\"]['totalReplyCount']\n",
    "\n",
    "                \n",
    "\n",
    "    df = pd.DataFrame({'Name': [i[0] for i in box], 'Comments': [i[1] for i in box], 'Time': [i[2] for i in box],\n",
    "                       'Likes': [i[3] for i in box], 'Reply Count': [i[4] for i in box]})\n",
    "        \n",
    "    sql_vids = pd.DataFrame([])\n",
    "\n",
    "    sql_vids = sql_vids.append(df, ignore_index = True)\n",
    "\n",
    "    return sql_vids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "                    part='contentDetails',\n",
    "                    playlistId = playlist_id,\n",
    "                    maxResults = 50,\n",
    "                    pageToken = next_page_token)\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ids = get_video_ids(youtube, 'PLqnslRFeH2Upcrywf-u2etjdxxkL8nl7E')\n",
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleaning_comments(comment):\n",
    "  comment = re.sub(\"[ğŸ˜ƒ|ğŸ¤£|ğŸ¤­|ğŸ¤£|ğŸ˜|ğŸ¤­|â¤ï¸|ğŸ‘|ğŸ´|ğŸ˜£|ğŸ˜ |ğŸ’ª|ğŸ™|ğŸ˜|ğŸŒº|ğŸŒ¸|ğŸŒ|ğŸŒ»|ğŸ’|ğŸ’“|ğŸ˜¥|ğŸ’”|ğŸ˜ª|ğŸ˜‘|ğŸ½|ğŸ˜¢|ğŸ˜‘|ğŸ˜‡|ğŸ’œ|ğŸª´|ğŸ™ŒğŸ»|ğŸ‡¨ğŸ‡¦|ğŸ•Š|ğŸ•¯|ğŸ˜­|ğŸ˜”|ğŸ’™|ğŸ¼|âœ|ğŸ‡¿]+\",'',str(comment))\n",
    "  comment = re.sub(\"[\\:|\\@|\\)|\\*|\\.|\\$|\\!|\\?|\\,|\\%|\\\"|\\(|\\-|\\â€|\\#|\\!|\\/|\\Â«|\\Â»|\\&|\\n|\\'|\\;|\\!|<|>|\\'|\\â€™|\\\\\\\\]+\",\" \",str(comment))\n",
    "  return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = lambda x: x.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\wled3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n",
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\1350749180.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sql_vids = sql_vids.append(df, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "ids = []\n",
    "\n",
    "for id in video_ids:\n",
    "    ids.append(id)\n",
    "\n",
    "    df = scrape_comments_with_replies(id)\n",
    "    df.drop([0], axis=0, inplace=True)\n",
    "    \n",
    "    df['Comments'] = df['Comments'].apply(cleaning_comments)\n",
    "    df['Comments'] = df['Comments'].apply(lower)\n",
    "\n",
    "    #Create scores col\n",
    "    df['Scores'] = df['Comments'].apply(lambda x: sid.polarity_scores(x))\n",
    "\n",
    "    #Create compund score\n",
    "    df['Compound'] = df['Scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "    #label based on score\n",
    "    df['Polarity'] = df['Compound'].apply(lambda c: 'neutral' if -0.05 < c < 0.05 else ('negative' if c < -0.05 else 'positive'))\n",
    "\n",
    "\n",
    "    g = df['Compound'].sum()\n",
    "    d = df['Compound'].count()\n",
    "\n",
    "    total_score = g / d    \n",
    "    scores.append(total_score)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(ids, scores)), columns =['video_id', 'avg polarity score']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):\n",
    "\n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "    \n",
    "    return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = get_video_details(youtube, video_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get channel stats\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    youtube: build object of Youtube API\n",
    "    channel_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    ------\n",
    "    dataframe with all channel stats for each channel ID\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # loop through items\n",
    "    for item in response[\"items\"]:\n",
    "        data = {'channelTitle': item['snippet']['title'],\n",
    "                'subscribers': item['statistics']['subscriberCount'],\n",
    "                'totalViews': item['statistics']['viewCount'],\n",
    "                'totalVideos': item['statistics']['videoCount']     \n",
    "        }\n",
    "        \n",
    "        all_data.append(data)\n",
    "        \n",
    "    return(pd.DataFrame(all_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = get_channel_stats(youtube, ['UCbXgNpp0jedKWcQiULLbDTA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df2)\n",
    "\n",
    "df = pd.merge(df, ch)\n",
    "\n",
    "df.to_csv(r'C:\\Users\\wled3\\yz2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wled3\\AppData\\Local\\Temp\\ipykernel_37064\\2990974202.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataf = data1.append(data2)\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(r'C:\\Users\\wled3\\ytunlabeled2.csv')\n",
    "\n",
    "data2 = pd.read_csv(r'C:\\Users\\wled3\\yz2.csv')\n",
    "\n",
    "dataf = data1.append(data2)\n",
    "\n",
    "dataf.to_csv(r'C:\\Users\\wled3\\ytunlabeled2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
